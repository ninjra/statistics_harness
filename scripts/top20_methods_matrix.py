#!/usr/bin/env python3
from __future__ import annotations

import argparse
import json
from dataclasses import asdict
from pathlib import Path
from typing import Any

import yaml


ROOT = Path(__file__).resolve().parents[1]


def _load_plugin_manifest(plugin_id: str) -> dict[str, Any]:
    path = ROOT / "plugins" / plugin_id / "plugin.yaml"
    data = yaml.safe_load(path.read_text(encoding="utf-8"))
    return data if isinstance(data, dict) else {}


def _top20_plugin_ids() -> list[str]:
    # Source of truth: plugin directories created by scaffold_top20_plugins.py
    ids = []
    for path in sorted((ROOT / "plugins").glob("analysis_*_v1/plugin.yaml")):
        data = yaml.safe_load(path.read_text(encoding="utf-8"))
        if isinstance(data, dict) and str(data.get("id") or "").endswith("_v1"):
            ids.append(str(data["id"]))
    # Keep only the Top20 doc IDs.
    wanted = {
        "analysis_param_near_duplicate_minhash_v1",
        "analysis_param_near_duplicate_simhash_v1",
        "analysis_frequent_itemsets_fpgrowth_v1",
        "analysis_association_rules_apriori_v1",
        "analysis_sequential_patterns_prefixspan_v1",
        "analysis_sequence_grammar_sequitur_v1",
        "analysis_biclustering_cheng_church_v1",
        "analysis_density_clustering_hdbscan_v1",
        "analysis_constrained_clustering_cop_kmeans_v1",
        "analysis_dependency_community_louvain_v1",
        "analysis_dependency_community_leiden_v1",
        "analysis_similarity_graph_spectral_clustering_v1",
        "analysis_graph_min_cut_partition_v1",
        "analysis_distribution_shift_wasserstein_v1",
        "analysis_burst_modeling_hawkes_v1",
        "analysis_daily_pattern_alignment_dtw_v1",
        "analysis_action_search_simulated_annealing_v1",
        "analysis_action_search_mip_batched_scheduler_v1",
        "analysis_discrete_event_queue_simulator_v1",
        "analysis_empirical_bayes_shrinkage_v1",
    }
    out = [pid for pid in sorted(set(ids)) if pid in wanted]
    return out


def _runtime_mode(plugin_id: str) -> str:
    if "action_search" in plugin_id or "queue_simulator" in plugin_id:
        return "in_memory_small"
    if "dependency_community" in plugin_id or "graph_min_cut" in plugin_id:
        return "graph_small"
    return "sql_first"


def _data_sources(plugin_id: str) -> list[str]:
    sources = ["normalized_template"]
    if "param_" in plugin_id or "itemsets" in plugin_id or "rules" in plugin_id or "clustering" in plugin_id:
        sources += ["parameter_entities", "parameter_kv", "row_parameter_link"]
    if "action_search" in plugin_id or "queue_simulator" in plugin_id:
        sources += ["plugin_results_v2:analysis_actionable_ops_levers_v1"]
    return sorted(set(sources))


def _overlaps(plugin_id: str) -> list[str]:
    overlaps: dict[str, list[str]] = {
        "analysis_sequential_patterns_prefixspan_v1": ["analysis_sequential_patterns_prefixspan"],
        "analysis_burst_modeling_hawkes_v1": ["analysis_hawkes_self_exciting", "analysis_term_burst_kleinberg"],
    }
    return overlaps.get(plugin_id, [])


def build_matrix() -> dict[str, Any]:
    rows = []
    for pid in _top20_plugin_ids():
        manifest = _load_plugin_manifest(pid)
        rows.append(
            {
                "plugin_id": pid,
                "name": manifest.get("name"),
                "depends_on": manifest.get("depends_on") or [],
                "capabilities": manifest.get("capabilities") or [],
                "runtime_mode": _runtime_mode(pid),
                "data_sources": _data_sources(pid),
                "output_kinds": ["actionable_ops_lever"],
                "primary_artifacts": [],
                "overlap_with_existing_plugins": _overlaps(pid),
            }
        )
    return {
        "generated_at": str(Path(__file__).name),
        "count": len(rows),
        "plugins": rows,
    }


def as_markdown(matrix: dict[str, Any]) -> str:
    rows = matrix.get("plugins") or []
    lines = ["# Top20 Additional Methods Plugins Matrix", ""]
    lines.append("Generated by `scripts/top20_methods_matrix.py`.")
    lines.append("")
    lines.append("| Plugin ID | Runtime | Data Sources | Depends On | Overlap |")
    lines.append("|---|---|---|---|---|")
    for row in rows:
        pid = str(row.get("plugin_id") or "")
        rm = str(row.get("runtime_mode") or "")
        ds = ", ".join(row.get("data_sources") or [])
        dep = ", ".join(row.get("depends_on") or [])
        ov = ", ".join(row.get("overlap_with_existing_plugins") or [])
        lines.append(f"| `{pid}` | `{rm}` | {ds} | {dep} | {ov} |")
    lines.append("")
    return "\n".join(lines)


def main() -> int:
    ap = argparse.ArgumentParser()
    ap.add_argument("--out-json", default="docs/top20_additional_methods_plugins_matrix.json")
    ap.add_argument("--out-md", default="docs/top20_additional_methods_plugins_matrix.md")
    ap.add_argument("--verify", action="store_true")
    args = ap.parse_args()

    matrix = build_matrix()
    out_json = ROOT / str(args.out_json)
    out_md = ROOT / str(args.out_md)
    out_json.write_text(json.dumps(matrix, indent=2, sort_keys=True) + "\n", encoding="utf-8")
    out_md.write_text(as_markdown(matrix), encoding="utf-8")

    if args.verify:
        if int(matrix.get("count") or 0) != 20:
            raise SystemExit(f"Expected 20 plugins, got {matrix.get('count')}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())

