#!/usr/bin/env python3
from __future__ import annotations

import argparse
import json
from datetime import datetime, timezone
from pathlib import Path
from typing import Any

from statistic_harness.core.storage import Storage
from statistic_harness.core.tenancy import get_tenant_context


ROOT = Path(__file__).resolve().parents[1]
DEFAULT_MATRIX = ROOT / "docs" / "plugin_data_access_matrix.json"
DEFAULT_OUT_JSON = ROOT / "docs" / "streaming_offenders_ranked.json"
DEFAULT_OUT_MD = ROOT / "docs" / "streaming_offenders_ranked.md"


def _now_iso() -> str:
    return datetime.now(timezone.utc).isoformat()


def _load_matrix(path: Path) -> list[dict[str, Any]]:
    payload = json.loads(path.read_text(encoding="utf-8"))
    return list(payload.get("plugins") or [])


def _fetch_exec_stats(storage: Storage) -> dict[str, dict[str, float]]:
    tenant_id = storage._tenant_id()  # noqa: SLF001 - script helper only
    out: dict[str, dict[str, float]] = {}
    with storage.connection() as conn:
        rows = conn.execute(
            """
            SELECT plugin_id,
                   AVG(COALESCE(duration_ms, 0)) AS avg_duration_ms,
                   MAX(COALESCE(max_rss, 0)) AS max_rss_kb,
                   COUNT(*) AS execution_count
            FROM plugin_executions
            WHERE tenant_id = ?
            GROUP BY plugin_id
            """,
            (tenant_id,),
        ).fetchall()
    for row in rows:
        plugin_id = str(row["plugin_id"] or "")
        out[plugin_id] = {
            "avg_duration_ms": float(row["avg_duration_ms"] or 0.0),
            "max_rss_kb": float(row["max_rss_kb"] or 0.0),
            "execution_count": float(row["execution_count"] or 0.0),
        }
    return out


def _score(avg_duration_ms: float, max_rss_kb: float) -> float:
    duration_component = avg_duration_ms / 1000.0
    rss_component = max_rss_kb / 1024.0
    return float(duration_component + rss_component)


def build_ranked(matrix_rows: list[dict[str, Any]], exec_stats: dict[str, dict[str, float]]) -> list[dict[str, Any]]:
    ranked: list[dict[str, Any]] = []
    for item in matrix_rows:
        if not bool(item.get("uses_dataset_loader_unbounded")):
            continue
        plugin_id = str(item.get("plugin_id") or "")
        stats = exec_stats.get(plugin_id, {})
        avg_duration_ms = float(stats.get("avg_duration_ms") or 0.0)
        max_rss_kb = float(stats.get("max_rss_kb") or 0.0)
        execution_count = int(stats.get("execution_count") or 0.0)
        ranked.append(
            {
                "plugin_id": plugin_id,
                "plugin_type": str(item.get("plugin_type") or ""),
                "uses_dataset_loader_unbounded": True,
                "avg_duration_ms": avg_duration_ms,
                "max_rss_kb": max_rss_kb,
                "execution_count": execution_count,
                "priority_score": _score(avg_duration_ms, max_rss_kb),
            }
        )
    ranked.sort(
        key=lambda row: (
            -float(row["priority_score"]),
            -float(row["max_rss_kb"]),
            -float(row["avg_duration_ms"]),
            str(row["plugin_id"]),
        )
    )
    return ranked


def _to_md(top_rows: list[dict[str, Any]], *, top_n: int) -> str:
    lines = [
        "# Streaming Offenders Ranked",
        "",
        "Generated by `scripts/rank_streaming_offenders.py`.",
        "",
        f"- top_n: {top_n}",
        "",
        "| Rank | Plugin | Type | Avg Duration (ms) | Max RSS (KB) | Executions | Priority Score |",
        "|---:|---|---|---:|---:|---:|---:|",
    ]
    for idx, row in enumerate(top_rows, start=1):
        lines.append(
            f"| {idx} | `{row['plugin_id']}` | {row['plugin_type']} | "
            f"{row['avg_duration_ms']:.1f} | {row['max_rss_kb']:.1f} | "
            f"{row['execution_count']} | {row['priority_score']:.2f} |"
        )
    lines.append("")
    return "\n".join(lines)


def main() -> int:
    parser = argparse.ArgumentParser(description="Rank unbounded dataset-loader plugins by telemetry hotspots.")
    parser.add_argument("--matrix-json", default=str(DEFAULT_MATRIX))
    parser.add_argument("--top-n", type=int, default=20)
    parser.add_argument("--out-json", default=str(DEFAULT_OUT_JSON))
    parser.add_argument("--out-md", default=str(DEFAULT_OUT_MD))
    args = parser.parse_args()

    matrix_rows = _load_matrix(Path(args.matrix_json))
    ctx = get_tenant_context()
    storage = Storage(ctx.db_path, ctx.tenant_id)
    exec_stats = _fetch_exec_stats(storage)
    ranked = build_ranked(matrix_rows, exec_stats)
    top_n = max(1, int(args.top_n))
    top_rows = ranked[:top_n]

    payload = {
        "schema_version": "streaming_offenders_ranked.v1",
        "generated_at": _now_iso(),
        "top_n": top_n,
        "total_candidates": len(ranked),
        "items": top_rows,
    }

    out_json = Path(args.out_json)
    out_md = Path(args.out_md)
    out_json.parent.mkdir(parents=True, exist_ok=True)
    out_md.parent.mkdir(parents=True, exist_ok=True)
    out_json.write_text(json.dumps(payload, indent=2, sort_keys=True) + "\n", encoding="utf-8")
    out_md.write_text(_to_md(top_rows, top_n=top_n), encoding="utf-8")
    print(str(out_json))
    print(str(out_md))
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
