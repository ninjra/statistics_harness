#!/usr/bin/env python3
from __future__ import annotations

import argparse
import json
from datetime import datetime, timezone
from pathlib import Path
from typing import Any

from statistic_harness.core.storage import Storage
from statistic_harness.core.tenancy import get_tenant_context


ROOT = Path(__file__).resolve().parents[1]


def _now_iso() -> str:
    return datetime.now(timezone.utc).isoformat()


def _status_counts(rows: list[dict[str, Any]]) -> dict[str, int]:
    out: dict[str, int] = {}
    for row in rows:
        status = str(row.get("status") or "unknown")
        out[status] = int(out.get(status, 0)) + 1
    return out


def _latest_completed_runs(storage: Storage, limit: int) -> list[str]:
    tenant_id = storage._tenant_id()  # noqa: SLF001 - script helper only
    with storage.connection() as conn:
        rows = conn.execute(
            """
            SELECT run_id
            FROM runs
            WHERE tenant_id = ? AND status IN ('completed', 'partial')
            ORDER BY created_at DESC, run_id DESC
            LIMIT ?
            """,
            (tenant_id, int(limit)),
        ).fetchall()
    return [str(row["run_id"]) for row in rows]


def _build_run_summary(storage: Storage, run_id: str) -> dict[str, Any]:
    run_row = storage.fetch_run(run_id) or {}
    plugin_rows = storage.fetch_plugin_results(run_id)
    return {
        "run_id": run_id,
        "status": run_row.get("status"),
        "dataset_version_id": run_row.get("dataset_version_id"),
        "run_seed": run_row.get("run_seed"),
        "requested_run_seed": run_row.get("requested_run_seed"),
        "plugin_count": len(plugin_rows),
        "status_counts": _status_counts(plugin_rows),
    }


def _render_markdown(items: list[dict[str, Any]]) -> str:
    lines = [
        "# Golden Release Evidence Summary",
        "",
        "Generated by `scripts/build_golden_release_evidence_pack.py`.",
        "",
        "| Run ID | Status | Dataset Version | Plugin Count | Status Counts |",
        "|---|---|---|---:|---|",
    ]
    for item in items:
        counts = ", ".join(f"{k}:{v}" for k, v in sorted((item.get("status_counts") or {}).items()))
        lines.append(
            f"| `{item.get('run_id', '')}` | {item.get('status', '')} | "
            f"`{item.get('dataset_version_id', '')}` | {item.get('plugin_count', 0)} | {counts} |"
        )
    lines.append("")
    return "\n".join(lines)


def main() -> int:
    parser = argparse.ArgumentParser(description="Build a deterministic golden-release evidence pack summary.")
    parser.add_argument("--run-id", action="append", default=[], help="Run ID(s) to include (repeatable).")
    parser.add_argument("--latest", type=int, default=3, help="Fallback latest runs if --run-id not provided.")
    parser.add_argument("--out-dir", default=str(ROOT / "docs" / "release_evidence"))
    args = parser.parse_args()

    out_dir = Path(args.out_dir)
    out_json = out_dir / "golden_release_summary.json"
    out_md = out_dir / "golden_release_summary.md"

    ctx = get_tenant_context()
    storage = Storage(ctx.db_path, ctx.tenant_id)
    run_ids = [str(x).strip() for x in (args.run_id or []) if str(x).strip()]
    if not run_ids:
        run_ids = _latest_completed_runs(storage, max(1, int(args.latest)))
    summaries = [_build_run_summary(storage, rid) for rid in run_ids]

    payload = {
        "schema_version": "golden_release_evidence.v1",
        "generated_at": _now_iso(),
        "run_ids": run_ids,
        "runs": summaries,
    }
    out_dir.mkdir(parents=True, exist_ok=True)
    out_json.write_text(json.dumps(payload, indent=2, sort_keys=True) + "\n", encoding="utf-8")
    out_md.write_text(_render_markdown(summaries), encoding="utf-8")
    print(str(out_json))
    print(str(out_md))
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
