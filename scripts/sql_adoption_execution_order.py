#!/usr/bin/env python3
from __future__ import annotations

import argparse
import json
from pathlib import Path
from typing import Any


ROOT = Path(__file__).resolve().parents[1]
PARTITION_PATH = ROOT / "docs" / "sql_adoption_partition_matrix.json"
ACCESS_PATH = ROOT / "docs" / "plugin_data_access_matrix.json"


def _load_json(path: Path) -> dict[str, Any]:
    if not path.exists():
        return {}
    try:
        payload = json.loads(path.read_text(encoding="utf-8"))
    except json.JSONDecodeError:
        return {}
    return payload if isinstance(payload, dict) else {}


def _pillar_scores(plugin_id: str, access_row: dict[str, Any]) -> dict[str, float]:
    pid = plugin_id.lower()
    speed = 2.0
    accuracy = 2.0
    reliability = 2.0
    explainability = 2.0

    if bool(access_row.get("uses_dataset_loader_unbounded")):
        speed += 1.0
        reliability += 0.5

    if "close_cycle" in pid:
        speed += 1.0
        reliability += 1.0
        accuracy += 0.5

    if any(token in pid for token in ("contention", "capacity", "queue", "revenue")):
        speed += 0.5
        accuracy += 0.5

    if any(token in pid for token in ("conformance", "dependency", "ideaspace", "recommendation")):
        accuracy += 0.5
        explainability += 0.5

    if "window" in pid or "drift" in pid:
        reliability += 0.5

    return {
        "speed": min(4.0, round(speed, 2)),
        "accuracy": min(4.0, round(accuracy, 2)),
        "reliability": min(4.0, round(reliability, 2)),
        "explainability": min(4.0, round(explainability, 2)),
    }


def _priority_score(pillars: dict[str, float]) -> float:
    values = list(pillars.values())
    avg = sum(values) / float(len(values))
    balance = min(values)
    return round(avg + (0.25 * balance), 3)


def generate_markdown(root: Path) -> str:
    partition = _load_json(PARTITION_PATH)
    access = _load_json(ACCESS_PATH)
    access_by_plugin = {
        row.get("plugin_id"): row
        for row in (access.get("plugins") or [])
        if isinstance(row, dict) and isinstance(row.get("plugin_id"), str)
    }

    group_a = sorted(partition.get("groups", {}).get("group_A_shared_layer_covered", []))
    group_b = sorted(partition.get("groups", {}).get("group_B_direct_sql_benefit", []))
    group_c = sorted(partition.get("groups", {}).get("group_C_not_applicable_reclassify", []))
    group_d = sorted(partition.get("groups", {}).get("group_D_optional_defer", []))

    ranked_rows: list[dict[str, Any]] = []
    for plugin_id in group_b:
        access_row = access_by_plugin.get(plugin_id, {})
        pillars = _pillar_scores(plugin_id, access_row)
        ranked_rows.append(
            {
                "plugin_id": plugin_id,
                "priority_score": _priority_score(pillars),
                "pillars": pillars,
                "uses_dataset_loader_unbounded": bool(access_row.get("uses_dataset_loader_unbounded")),
            }
        )
    ranked_rows.sort(key=lambda row: (-row["priority_score"], row["plugin_id"]))

    lines: list[str] = []
    lines.append("# SQL Adoption Execution Order")
    lines.append("")
    lines.append("Generated by `scripts/sql_adoption_execution_order.py`.")
    lines.append("")
    lines.append("## Partition Summary")
    lines.append(f"- Group A (shared layer covered): {len(group_a)}")
    lines.append(f"- Group B (direct SQL benefit): {len(group_b)}")
    lines.append(f"- Group C (not applicable reclassify): {len(group_c)}")
    lines.append(f"- Group D (optional defer): {len(group_d)}")
    lines.append("")
    lines.append("## Group B Priority Queue")
    lines.append("")
    lines.append("| Rank | Plugin | Priority | Speed | Accuracy | Reliability | Explainability | Unbounded Loader |")
    lines.append("|---:|---|---:|---:|---:|---:|---:|---:|")
    for idx, row in enumerate(ranked_rows, start=1):
        pillars = row["pillars"]
        lines.append(
            "| "
            + " | ".join(
                [
                    str(idx),
                    f"`{row['plugin_id']}`",
                    f"{row['priority_score']:.3f}",
                    f"{pillars['speed']:.1f}",
                    f"{pillars['accuracy']:.1f}",
                    f"{pillars['reliability']:.1f}",
                    f"{pillars['explainability']:.1f}",
                    str(int(row["uses_dataset_loader_unbounded"])),
                ]
            )
            + " |"
        )
    lines.append("")
    lines.append("## Notes")
    lines.append("- Group A should be closed via shared stat-plugin SQL enhancements before plugin-local edits.")
    lines.append("- Group B should be implemented in rank order and re-scored after each batch.")
    lines.append("- Groups C/D are intentionally deferred until evidence changes.")
    lines.append("")
    return "\n".join(lines)


def main() -> int:
    ap = argparse.ArgumentParser()
    ap.add_argument("--out-md", default="docs/sql_adoption_execution_order.md")
    ap.add_argument("--verify", action="store_true")
    args = ap.parse_args()

    md_text = generate_markdown(ROOT) + "\n"
    out_md = (ROOT / args.out_md).resolve()

    if args.verify:
        if not out_md.exists() or out_md.read_text(encoding="utf-8") != md_text:
            return 2
        return 0

    out_md.parent.mkdir(parents=True, exist_ok=True)
    out_md.write_text(md_text, encoding="utf-8")
    print(f"out_md={out_md}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
